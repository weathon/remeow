{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lumaai import LumaAI\n",
    "\n",
    "# read .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = LumaAI(\n",
    "    auth_token=os.environ[\"LUMA_TOKEN\"],\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "\n",
    "\n",
    "def soft_edge(size):\n",
    "\n",
    "  width, height = size\n",
    "  mask = Image.new(\"L\", (width, height), 0)\n",
    "  draw = ImageDraw.Draw(mask)\n",
    "  edge_width = min(width, height) // 10\n",
    "\n",
    "  for i in range(edge_width):\n",
    "      draw.rectangle([i, i, width - i - 1, height - i - 1], fill=i * (255 // edge_width))\n",
    "\n",
    "  blurred_mask = mask.filter(ImageFilter.GaussianBlur(radius=edge_width / 2))\n",
    "  transparency_array = np.array(blurred_mask)\n",
    "\n",
    "  return transparency_array/transparency_array.max()\n",
    "\n",
    "\n",
    "\n",
    "generation = client.generations.image.create(\n",
    "  prompt=\"image of forest\",\n",
    ")\n",
    "completed = False\n",
    "while not completed:\n",
    "  generation = client.generations.get(id=generation.id)\n",
    "  if generation.state == \"completed\":\n",
    "    completed = True\n",
    "  elif generation.state == \"failed\":\n",
    "    raise RuntimeError(f\"Generation failed: {generation.failure_reason}\")\n",
    "  print(\"Dreaming\")\n",
    "  time.sleep(2)\n",
    "\n",
    "image_url = generation.assets.image\n",
    "\n",
    "# download image_url into PIL\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "response = requests.get(image_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "background = img\n",
    "\n",
    "import cv2\n",
    "video_path = \"smoke.mp4\"\n",
    "import random\n",
    "video = cv2.VideoCapture(video_path)\n",
    "masks = []\n",
    "frames = []\n",
    "blended = []\n",
    "\n",
    "\n",
    "slience_frames = 10 * 30\n",
    "for i in range(slience_frames):\n",
    "  masks.append(np.zeros((512, 512), dtype=np.uint8))\n",
    "  blended.append(background)\n",
    "\n",
    "\n",
    "while video.isOpened():\n",
    "  background = img.resize((512, 512)).convert(\"L\")\n",
    "  ret, frame = video.read()\n",
    "  size = random.randint(128, 256)\n",
    "  locx = random.randint(0, 512 - size[0])\n",
    "  locy = random.randint(0, 512 - size[1])\n",
    "  if not ret:\n",
    "    break\n",
    "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  gray = cv2.resize(gray, (512, 512))\n",
    "\n",
    "  gray = Image.fromarray(gray).resize((size, size))\n",
    "  \n",
    "  white = Image.new('RGB', (512, 512), (255, 255, 255))\n",
    "\n",
    "  canvas = Image.new('L', (512, 512), (0))\n",
    "  softedge_mask = Image.fromarray((soft_edge((size, size)) * 255).astype(\"uint8\"))\n",
    "  # softedge_mask = Image.new('L', (512, 512), (0))\n",
    "  # softedge_mask.paste(softedge_mask, (100, 100))\n",
    "  canvas.paste(gray, (locx, locy), mask=softedge_mask)\n",
    "  gray = np.array(canvas)\n",
    "  mask = gray > 0.1 * 255\n",
    "  gray = Image.fromarray(gray.astype(\"uint8\"))\n",
    "\n",
    "  masks.append(mask)\n",
    "  frames.append(gray)\n",
    "  background.paste(white, (100, 100), mask=Image.fromarray((np.array(gray)//2 * mask).astype(\"uint8\")))\n",
    "  blended.append(background)\n",
    "\n",
    "# save blended into video\n",
    "os.mkdir(\"in\")\n",
    "os.mkdir(\"gt\")\n",
    "for i in range(len(blended)):\n",
    "  blended[i].save(f\"in/{i}.png\")\n",
    "  masks[i].save(f\"gt/{i}.png\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
